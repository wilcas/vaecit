---
title: "Sanity Check and PCA Comparison"
author: "William Casazza"
date: "May 8, 2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
```
# CIT sanity check
At this point I have run a bunch of experiments with "blocky"  genotype matrices, with the goal that for PCA the first PC should the majority of variance in matrices I've designed to have correlated genotypes. What I did to generate these matrices was generate a number of random genotypes, and then make varied percentages of the remaining genotypes by adding random noises to the initial set and copying the result over new columns. 

First I need to aggregate these sensibly:
```{r}
get_sanity_results <- function(path){
  sanity_results <- list()
  for(f in dir(path, full.names = TRUE)){
    tmp_df <- read.csv(f)
    tmp_df$scenario <- gsub(".*/cit_(.*)_([0-9]*)_PCs_([0-9]*)_gen_(.*)_split.csv", "\\1", f)
    tmp_df$num_pc <- gsub(".*/cit_(.*)_([0-9]*)_PCs_([0-9]*)_gen_(.*)_split.csv", "\\2", f)
    tmp_df$num_genotype <- gsub(".*/cit_(.*)_([0-9]*)_PCs_([0-9]*)_gen_(.*)_split.csv", "\\3", f)
    tmp_df$split <- gsub(".*/cit_(.*)_([0-9]*)_PCs_([0-9]*)_gen_(.*)_split.csv", "\\4", f)
    sanity_results[[f]] <- tmp_df
  }
  sanity_df <- bind_rows(sanity_results) %>%
    mutate(
      Scenario = plyr::mapvalues(
        scenario,
        from = c("caus1","ind1","null"), 
        to = c("Full Mediation", "Independent Association", "Null")))
  
  str(sanity_df)
  return(sanity_df)
}
sanity_df <- get_sanity_results("../data/sanity_check/")
sanity_df_perm <- get_sanity_results("../data/sanity_check_perm/")

```
Okay, just given this peek things are looking good, lets plot to get a nice overall view of the results we have here:
```{r}
plot_pvals <- function(sanity_df){
  split_level <- c("100", "80-20", "50-50", "33-33-34", "all-25", "all-20", "all")
  sm_split <- c("80-20", "50-50", "33-33-34", "all-25", "all-20")

  p1 <- ggplot(
      sanity_df %>% 
      filter(as.numeric(num_genotype) < 50,!(split %in% sm_split & num_genotype == 1)) %>% 
      mutate(split = fct_relevel(split, split_level)), 
      aes(omni_p , fill = Scenario)) + 
    geom_histogram(position = "identity", alpha = 0.6) + 
    scale_fill_manual(values = c("blue", "red", "gold")) + 
    labs(y = "Count (100 simulations per model)",x = "P Value Epigenetic Mediation") + 
    ggtitle("Capturing Epigenetic Mediation of Genotype PC1") +
    theme_minimal(base_family = "Arial") +
    theme(axis.text.x = element_text(hjust = 1,vjust =1,angle = 90)) +
    scale_y_continuous(limits=c(0,100)) + 
    facet_grid(num_genotype ~ split)
  p2 <- ggplot(
      sanity_df %>% 
      filter(as.numeric(num_genotype) >= 50) %>% 
      mutate(split = fct_relevel(split, split_level)),
      aes(omni_p , fill = Scenario)) + 
    geom_histogram(position = "identity", alpha = 0.6) + 
    scale_fill_manual(values = c("blue", "red", "gold")) + 
    labs(y = "Count (100 simulations per model)",x = "P Value Epigenetic Mediation") + 
    ggtitle("Capturing Epigenetic Mediation of Genotype PC1") +
    theme_minimal(base_family = "Arial") +
    theme(axis.text.x = element_text(hjust = 1,vjust =1,angle = 90)) +
    scale_y_continuous(limits=c(0,100)) + 
    facet_grid(num_genotype ~ split)
  print(p1)
  print(p2)
}
plot_pvals(sanity_df)
```
Great, we see that with more distinct groups we get a lower ability to detect a the full mediation scenario.
Let's just see how well we capture variance in genotype in each scenario with their first PC:
```{r}
plot_var_explained <- function(sanity_df){
  split_level <- c("100", "80-20", "50-50", "33-33-34", "all-25", "all-20", "all")
  sm_split <- c("80-20", "50-50", "33-33-34", "all-25", "all-20")
  p1 <- ggplot(
      sanity_df %>% 
      filter(as.numeric(num_genotype) < 50, !(split %in% sm_split & num_genotype == 1)) %>% 
      mutate(split = fct_relevel(split, split_level),
             var_explained_pcs = var_explained_pcs * 100),
      aes(Scenario, var_explained_pcs, fill = Scenario)) + 
    geom_boxplot() + 
    scale_fill_manual(values = c("blue", "red", "gold")) + 
    labs(y = "Percent Variance Explained PC1",x = "P Value Epigenetic Mediation") + 
    ggtitle("Capturing Epigenetic Mediation of Genotype PC1") +
    theme_minimal(base_family = "Arial") +
    theme(axis.text.x = element_text(hjust = 1,vjust =1,angle = 90)) +
    facet_grid(num_genotype ~ split, scales = "free_y")
  p2 <- ggplot(
      sanity_df %>% 
      filter(as.numeric(num_genotype) >= 50) %>% 
      mutate(split = fct_relevel(split, split_level),
             var_explained_pcs = var_explained_pcs * 100),
      aes(Scenario, var_explained_pcs, fill = Scenario)) + 
    geom_boxplot() + 
    scale_fill_manual(values = c("blue", "red", "gold")) + 
    labs(y = "Percent Variance Explained PC1",x = "P Value Epigenetic Mediation") + 
    ggtitle("Capturing Epigenetic Mediation of Genotype PC1") +
    theme_minimal(base_family = "Arial") +
    theme(axis.text.x = element_text(hjust = 1,vjust =1,angle = 90)) +
    facet_grid(num_genotype ~ split)
  print(p1)
  print(p2)
}
plot_var_explained(sanity_df)
```
Variance explained by the first PC goes down as we vary correlated groups, in the case that we just have independent binomials as genotype, we explain similar amount of variance in genotype with PC1 as we do with random noise + repeats of one genotype.

We get inflated results for independent and full mediation scenarios if we use a semi-parametric test:
```{r}
plot_pvals(sanity_df_perm)
plot_var_explained(sanity_df_perm)
```


# PCA CIT Comparison to xQTL Paper
First we need to load in the data and match up results:
```{r}
cit_df <- read.table("../data/rosmap_cit_pca/CIT_groupby_order.txt", header = TRUE)
dim(cit_df)
head(cit_df)
pca_cit_df <- read.csv("../data/rosmap_cit_pca/pca_1_latent_cit.csv")
dim(pca_cit_df)
head(pca_cit_df)
pca_cit_rev_df <- read.csv("../data/rosmap_cit_pca/rev_pca_1_latent_cit.csv") %>%
  rename(rev_p1=p1,rev_p2=p2,rev_p3=p3,rev_p4=p4,rev_omni_p=omni_p)
pca_cit_approx_df <- read.csv("../data/rosmap_cit_pca/perm_test_pca_1_latent_cit.csv") %>% 
  rename(approx_p1=p1,approx_p2=p2,approx_p3=p3,approx_p4=p4,approx_omni_p=omni_p)
merged_cit_df <- cbind(
  cit_df[c("snp", "probes","peaks", "pCausal","pReact","gene")],
  pca_cit_df[c("p1","p2","p3","p4","omni_p")],
  pca_cit_rev_df[c("rev_p1","rev_p2","rev_p3","rev_p4","rev_omni_p")],
  pca_cit_approx_df[c("approx_p1","approx_p2","approx_p3","approx_p4","approx_omni_p")])
head(merged_cit_df)
merged_cit_df %>% group_by(probes,peaks,gene) %>% summarize(count = n()) %>%
  ggplot(aes(x = "Number of epigenetic terms shared per gene", y = count)) + geom_violin(width = 0.5)
```
Okay, that last plot means that I made an incorrect assumption in how to go about plotting these tests. Really, for each p value I have in the PCA version, I actually have multiple snp-relative p values I am comparing in the single version (for the case where i have shared epigenetic sets). I can/should change my script later to also group on sets of epigenetic marks, but to get a sense of how the rest of my pipeline worked let's group things properly before plotting:
```{r}
grouped_cit_df <- merged_cit_df %>% 
  group_by(probes,peaks) %>% 
  summarize(
    omni_p = max(omni_p),
    rev_omni_p = max(rev_omni_p),
    approx_omni_p = max(approx_omni_p),
    maxpCausal = max(pCausal),
    minpCausal = min(pCausal),
    meanpCausal = mean(pCausal),
    maxpReact = max(pReact),
    minpReact = min(pReact),
    meanpReact = mean(pReact)
  )
head(grouped_cit_df)
```


Since I'm a nice person, I made these tables have the same order per test, so I just need to plot p values along the same axes for a nice comparison:
```{r}
library(ggrepel)
library(cowplot)
p1 <- ggplot(grouped_cit_df, aes(x = -log10(omni_p), y = -log10(meanpCausal))) +
  geom_point()+
  scale_y_continuous(limits = c(0,30)) + 
  labs(caption = sprintf("Correlation = %f", cor(grouped_cit_df$omni_p,grouped_cit_df$meanpCausal)))

p2 <-ggplot(grouped_cit_df, aes(x = -log10(omni_p), y = -log10(maxpCausal))) +
  geom_point()+
  scale_y_continuous(limits = c(0,30)) + 
  labs(caption = sprintf("Correlation = %f", cor(grouped_cit_df$omni_p,grouped_cit_df$maxpCausal)))

p3 <-ggplot(grouped_cit_df, aes(x = -log10(omni_p), y = -log10(minpCausal))) +
  geom_point()+
  scale_y_continuous(limits = c(0,30)) + 
  labs(caption = sprintf("Correlation = %f", cor(grouped_cit_df$omni_p,grouped_cit_df$minpCausal)))

p4 <-ggplot(grouped_cit_df, aes(x = -log10(approx_omni_p), y = -log10(meanpCausal))) +
  geom_point()+
  scale_y_continuous(limits = c(0,30)) + 
  labs(caption = sprintf("Correlation = %f", cor(grouped_cit_df$approx_omni_p,grouped_cit_df$meanpCausal)))

p5 <-ggplot(grouped_cit_df, aes(x = -log10(approx_omni_p), y = -log10(maxpCausal))) +
  geom_point()+
  scale_y_continuous(limits = c(0,30)) + 
  labs(caption = sprintf("Correlation = %f", cor(grouped_cit_df$approx_omni_p,grouped_cit_df$maxpCausal)))

p6 <-ggplot(grouped_cit_df, aes(x = -log10(approx_omni_p), y = -log10(minpCausal))) +
  geom_point()+
  scale_y_continuous(limits = c(0,30)) + 
  labs(caption = sprintf("Correlation = %f", cor(grouped_cit_df$approx_omni_p,grouped_cit_df$minpCausal)))
plot_grid(p1,p2,p3,p4,p5,p6,labels="auto")
```

Pretty discouraging, lets see how my individual results compare to what's published, note that I don't use any approximation for test 4 of the CIT, so this is a preliminary comparison, not a definitive result:
```{r}
library(cowplot)
cit_rep_df <- read.csv("../data/rosmap_complete_rep/rev_cit_sanity_check.csv")
cit_rep_approx_df <- read.csv("../data/rosmap_complete_rep/perm_test_cit_sanity_check.csv") %>%
  rename(approx_p1 = p1,approx_p2 = p2,approx_p3 = p3,approx_p4 = p4,approx_omni_p = omni_p)
cit_rep_approx_fix_df <- read.csv("../data/rosmap_complete_rep/perm_test_cit_pca_fix_sanity_check.csv") %>%
    rename(approx_fix_p1 = p1,approx_fix_p2 = p2,approx_fix_p3 = p3,approx_fix_p4 = p4,approx_fix_omni_p = omni_p)

rep_merged_df <- cbind(
  cit_df[c("snp", "probes","peaks", "pCausal","pReact","gene")],
  cit_rep_df[c("p1","p2","p3","p4","omni_p")],
  cit_rep_approx_df[c("approx_p1","approx_p2","approx_p3","approx_p4","approx_omni_p")],
  cit_rep_approx_fix_df[c("approx_fix_p1","approx_fix_p2","approx_fix_p3","approx_fix_p4","approx_fix_omni_p")] )

head(rep_merged_df)
rep_merged_df
p1 <- ggplot(rep_merged_df, aes(-log10(pmax(approx_fix_p3, approx_fix_p4)),-log10(pCausal))) + geom_point() +
  labs(caption = sprintf(
    "Correlation: %f", 
    cor(
      -log10(pmax(rep_merged_df$approx_fix_p3, rep_merged_df$approx_fix_p4)),
      -log10(rep_merged_df$pCausal))))

p2 <- ggplot(rep_merged_df, aes(-log10(approx_fix_omni_p),-log10(pCausal))) + geom_point() +
  labs(caption = sprintf(
    "Correlation: %f", 
    cor(
      -log10(rep_merged_df$approx_fix_omni_p),
      -log10(rep_merged_df$pCausal))))
gather(rep_merged_df,key = "test",value = "pvalue", approx_fix_p1, approx_fix_p2, approx_fix_p3, approx_fix_p4, approx_fix_omni_p) %>%
  ggplot(aes(pvalue)) + geom_histogram() + facet_wrap(~ test)
plot_grid(p1,p2)
```
No clue how well its working here, time to plot:
```{r}
ggplot(rep_merged_df,aes(-log10(omni_p),-log10(pReact))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$omni_p,rep_merged_df$pReact)))
ggplot(rep_merged_df,aes(-log10(p1),-log10(pReact))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$p1,rep_merged_df$pReact)))
ggplot(rep_merged_df,aes(-log10(p2),-log10(pReact))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$p2,rep_merged_df$pReact)))
ggplot(rep_merged_df,aes(-log10(p3),-log10(pReact))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$p3,rep_merged_df$pReact)))
ggplot(rep_merged_df,aes(-log10(p4),-log10(pReact))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$p4,rep_merged_df$pReact)))
```

Okay, so I should be looking to my pipeline code for possible bugs. I am positive that my code to match up samples works correctly, however here are the things I think are most likely incorrect:
* Data processing pipeline (normalization, removal of principal components etc)
* possibly the datasets I'm using (unlikely for genotype, could be what I'm using for methylation and acetylation, although I did check this twice at separate points with Bernard, I still may be confused)
* How I'm computing epigenome PCs `--checked this, was using scaled left singular vectors instead of projection of data into pc space`
* The semi-parametric test in condition 4 of CIT `possible memory leak, but seem to be correct in solving`
* some sort of truncation of floating point numbers
**found bugs**
Those shown addressed above and:
* error with CIT test 2 that went unnoticed in simulation data

Here's the final proof that I do or don't have a bug in the pipeline (attempt at exact replication):
```{r}
ggplot(rep_merged_df,aes(-log10(approx_omni_p),-log10(pCausal))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$approx_omni_p,rep_merged_df$pCausal)))
ggplot(rep_merged_df,aes(-log10(approx_p1),-log10(pCausal))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$approx_p1,rep_merged_df$pCausal)))
ggplot(rep_merged_df,aes(-log10(approx_p2),-log10(pCausal))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$approx_p2,rep_merged_df$pCausal)))
ggplot(rep_merged_df,aes(-log10(approx_p3),-log10(pCausal))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$approx_p3,rep_merged_df$pCausal)))
ggplot(rep_merged_df,aes(-log10(approx_p4),-log10(pCausal))) + 
  geom_point() + 
  labs(caption = sprintf("Correlation = %f", cor(rep_merged_df$approx_p4,rep_merged_df$pCausal)))
ggplot(rep_merged_df,aes(-log10(pmax(approx_p3,approx_p4)),-log10(pCausal))) + 
geom_point() +
  labs(caption = sprintf("Correlation = %f", cor(pmax(rep_merged_df$approx_p3,rep_merged_df$approx_p4), rep_merged_df$pCausal)))
```

